{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI Assistant API\n",
        "\n",
        "## Install OpenAI API"
      ],
      "metadata": {
        "id": "YGuqsop5Zpla"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxSg_6Ki-7yC"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai  > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Create OpenAI client\n",
        "client = OpenAI(api_key=userdata.get('openaiKey'))"
      ],
      "metadata": {
        "id": "C8wWeuZt_AHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading Data\n",
        "\n",
        "Note that REST API of OpenAI returns paged results. Therefore, we have to loop over the pages.\n"
      ],
      "metadata": {
        "id": "BLztw33haa_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For demo purposes, we limit the page size to 3 items.\n",
        "assistants = client.beta.assistants.list(limit=3, order=\"asc\")\n",
        "\n",
        "while True:\n",
        "    if assistants.first_id:\n",
        "        # For illustration purposes, we print the first and list ID of the page\n",
        "        print(f\"Page from {assistants.first_id} to {assistants.last_id}\")\n",
        "\n",
        "    # Print all records of the page\n",
        "    for a in assistants.data:\n",
        "        print(f\"\\t{a.name} ({a.id})\")\n",
        "\n",
        "    if not assistants.has_next_page():\n",
        "        # No more pages, exit the loop\n",
        "        break\n",
        "\n",
        "    # Get next page\n",
        "    print(\"Reading next page...\")\n",
        "    assistants = assistants.get_next_page()\n"
      ],
      "metadata": {
        "id": "NWv8SMuR_Rpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Methods"
      ],
      "metadata": {
        "id": "BTSVmnls7bXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_assistant(name, client):\n",
        "    \"\"\"Checks if OpenAI assistant with given name exists.\n",
        "\n",
        "    Returns assistant or None if it does not exist.\n",
        "    \"\"\"\n",
        "    assistants = client.beta.assistants.list()\n",
        "    while True:\n",
        "        for assistant in assistants.data:\n",
        "            if assistant.name == name:\n",
        "                return assistant\n",
        "\n",
        "        if not assistants.has_next_page():\n",
        "            break\n",
        "\n",
        "        assistants = assistants.get_next_page()\n",
        "\n",
        "    return None\n",
        "\n",
        "def get_file(name, client):\n",
        "    \"\"\"Checks if file with given name exists.\n",
        "\n",
        "    Returns file or None if it does not exist.\n",
        "    \"\"\"\n",
        "    files = client.files.list()\n",
        "    file = [ x for x in files if x.filename == name]\n",
        "    if file:\n",
        "        return file[0]\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "aPJtf1_GbB43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Files\n",
        "\n",
        "Files can be added to assistants and messages. They are useful for retrieval and\n",
        "code interpreter tools."
      ],
      "metadata": {
        "id": "seqc5UCg7fNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = get_file(\"qualifikationsprofil.md\", client)\n",
        "if not file:\n",
        "    print(\"File does not exist yet, uploading it...\")\n",
        "    file = client.files.create(file=open(\"qualifikationsprofil.md\", \"rb\"), purpose=\"assistants\")\n",
        "    print(f\"New file uploaded ({file.id})\")\n",
        "else:\n",
        "    print(f\"File already exists ({file.id})\")"
      ],
      "metadata": {
        "id": "foGtGayXm3hK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create/Update Assistant"
      ],
      "metadata": {
        "id": "m8r1Bn7x7pJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ASSISTANT_NAME = \"Bildungsberatungsassistent\"\n",
        "ASSISTANT_DESC = \"Assistent, der Sch端lerInnen bei der Schulauswahl hilft\"\n",
        "ASSISTANT_MODEL = \"gpt-4-1106-preview\"\n",
        "ASSISTANT_INSTRUCTIONS = \"\"\"\n",
        "Du bist ein Assistent, der Sch端lerInnen hilft, festzustellen, ob unsere Schule\n",
        "die richtige f端r sie ist. Daf端r beantworte Fragen zum Qualifikationsprofil\n",
        "unserer AbsolventInnen auf Basis der Datei _qualifikationsprofil.md_. Beantworte\n",
        "NUR Fragen zum Qualifikationsprofil. Verwende NUR die Informationen aus der\n",
        "Datei.\n",
        "\"\"\"\n",
        "METADATA = {\"project\": \"OpenAI API Video Tutorial\"}\n",
        "\n",
        "assistant_data = {\n",
        "    \"model\": ASSISTANT_MODEL,\n",
        "    \"name\": ASSISTANT_NAME,\n",
        "    \"description\": ASSISTANT_DESC,\n",
        "    \"instructions\": ASSISTANT_INSTRUCTIONS,\n",
        "    \"metadata\": METADATA,\n",
        "    \"tools\": [{\"type\": \"retrieval\"}],\n",
        "    \"file_ids\": [file.id],\n",
        "}\n",
        "\n",
        "assistant = get_assistant(ASSISTANT_NAME, client)\n",
        "if not assistant:\n",
        "    print(\"Assistant does not exist yet, creating it...\")\n",
        "    assistant = client.beta.assistants.create(**assistant_data)\n",
        "    print(f\"New assistant created ({assistant.id})\")\n",
        "else:\n",
        "    print(f\"Assistant already exists ({assistant.id}), updating it...\")\n",
        "    assistant_data[\"assistant_id\"] = assistant.id\n",
        "    assistant = client.beta.assistants.update(**assistant_data)\n",
        "    print(f\"Assistant updated\")\n"
      ],
      "metadata": {
        "id": "IXKa8swkax9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer Question With Retrieval Tool"
      ],
      "metadata": {
        "id": "yIg4dm6K7rfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pprint\n",
        "\n",
        "QUESTION = \"Haben AbsolventInnen der Schule eine Ausbildung bzgl. Projektmanagement?\"\n",
        "\n",
        "# Here we create the thread and the run separately. Note that there is an\n",
        "# API (https://platform.openai.com/docs/api-reference/runs/createThreadAndRun)\n",
        "# with which you could create a thread and start a run in one go.\n",
        "\n",
        "thread = client.beta.threads.create(\n",
        "    messages=[{\"role\": \"user\", \"content\": QUESTION}],\n",
        "    metadata=METADATA,\n",
        ")\n",
        "\n",
        "run = client.beta.threads.runs.create(\n",
        "    thread_id=thread.id,\n",
        "    assistant_id=assistant.id,\n",
        "    metadata=METADATA,\n",
        ")\n",
        "\n",
        "while True:\n",
        "    print(\"Sleeping for a moment to give OpenAI time to think...\")\n",
        "    time.sleep(3)\n",
        "\n",
        "    run = client.beta.threads.runs.retrieve(\n",
        "        run_id=run.id,\n",
        "        thread_id=thread.id,\n",
        "    )\n",
        "    print(f\"Run status: {run.status}\")\n",
        "\n",
        "    # Note that the thread API returns a paged result. To keep things simple,\n",
        "    # we assume that no paging is necessary (i.e. we have less than 100\n",
        "    # steps).\n",
        "    steps = client.beta.threads.runs.steps.list(\n",
        "        run_id=run.id,\n",
        "        thread_id=thread.id,\n",
        "        limit=100\n",
        "    )\n",
        "    for step in steps:\n",
        "        print(f\"\\t{step.type}: {step.status}\")\n",
        "\n",
        "    if run.status == \"completed\":\n",
        "        break;\n",
        "\n",
        "# Get the last message and print it on the screen\n",
        "messages = client.beta.threads.messages.list(\n",
        "    thread_id=thread.id,\n",
        "    limit=100)\n",
        "pprint.pprint(messages.data[0].content[0].text.value)\n",
        "\n",
        "# Note that you can get annotations, too. In the case of the retrieval tool,\n",
        "# annotations contain sources from uploaded files.\n",
        "messages.data[0].content[0].text.annotations[0]"
      ],
      "metadata": {
        "id": "lPvu5_tqxB9p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}