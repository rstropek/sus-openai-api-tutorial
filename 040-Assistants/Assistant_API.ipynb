{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI Assistant API\n",
        "\n",
        "## Install OpenAI API"
      ],
      "metadata": {
        "id": "YGuqsop5Zpla"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RxSg_6Ki-7yC"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai  > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Create OpenAI client\n",
        "client = OpenAI(api_key=userdata.get('openaiKey'))"
      ],
      "metadata": {
        "id": "C8wWeuZt_AHF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading Data\n",
        "\n",
        "Note that REST API of OpenAI returns paged results. Therefore, we have to loop over the pages.\n"
      ],
      "metadata": {
        "id": "BLztw33haa_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For demo purposes, we limit the page size to 3 items.\n",
        "assistants = client.beta.assistants.list(limit=3, order=\"asc\")\n",
        "\n",
        "while True:\n",
        "    if assistants.first_id:\n",
        "        # For illustration purposes, we print the first and list ID of the page\n",
        "        print(f\"Page from {assistants.first_id} to {assistants.last_id}\")\n",
        "\n",
        "    # Print all records of the page\n",
        "    for a in assistants.data:\n",
        "        print(f\"\\t{a.name} ({a.id})\")\n",
        "\n",
        "    if not assistants.has_next_page():\n",
        "        # No more pages, exit the loop\n",
        "        break\n",
        "\n",
        "    # Get next page\n",
        "    print(\"Reading next page...\")\n",
        "    assistants = assistants.get_next_page()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWv8SMuR_Rpt",
        "outputId": "dbdd37af-ab84-4219-c0e4-a9e661d5422f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page from asst_W5oK6XjlaJ4oohNtAIvqBwkF to asst_whqudtXh0wezn79broNeHrKa\n",
            "\tFundraising Assistant (asst_W5oK6XjlaJ4oohNtAIvqBwkF)\n",
            "\tAssistant for suggesting what to do in Vienna (asst_PPs1lJD0WwAeNTGC2XS44uoI)\n",
            "\tRainer's Assistant (asst_whqudtXh0wezn79broNeHrKa)\n",
            "Reading next page...\n",
            "Page from asst_5KsvX6sMeofGEZ32vh0IO3eQ to asst_9a2QtzsgBlbRRjI3MXoJxEaq\n",
            "\tBilal's Assistant (asst_5KsvX6sMeofGEZ32vh0IO3eQ)\n",
            "\tRothner Bot (asst_PyUBeGimRgwLNKFQnqZtSVEg)\n",
            "\tErik's Assistant (asst_9a2QtzsgBlbRRjI3MXoJxEaq)\n",
            "Reading next page...\n",
            "Page from asst_rdX2olFowfMVRLKqFxN3VgYI to asst_E5LTsTcfKdSCGoYREWME0851\n",
            "\tFD's Assistant (asst_rdX2olFowfMVRLKqFxN3VgYI)\n",
            "\tIF190138 Assistant (asst_7QUhdqpSX19in4tOEjjpE5ws)\n",
            "\tThomas Assistant (asst_E5LTsTcfKdSCGoYREWME0851)\n",
            "Reading next page...\n",
            "Page from asst_7IhJ2pxpu1aB8Q0ULkAHVPK9 to asst_to5sKCyedxax4uBQCe4ZJ2ax\n",
            "\tRob's Assistant (asst_7IhJ2pxpu1aB8Q0ULkAHVPK9)\n",
            "\tEli's Assistant (asst_to5sKCyedxax4uBQCe4ZJ2ax)\n",
            "Reading next page...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Methods"
      ],
      "metadata": {
        "id": "BTSVmnls7bXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_assistant(name, client):\n",
        "    \"\"\"Checks if OpenAI assistant with given name exists.\n",
        "\n",
        "    Returns assistant or None if it does not exist.\n",
        "    \"\"\"\n",
        "    assistants = client.beta.assistants.list()\n",
        "    while True:\n",
        "        for assistant in assistants.data:\n",
        "            if assistant.name == name:\n",
        "                return assistant\n",
        "\n",
        "        if not assistants.has_next_page():\n",
        "            break\n",
        "\n",
        "        assistants = assistants.get_next_page()\n",
        "\n",
        "    return None\n",
        "\n",
        "def get_file(name, client):\n",
        "    \"\"\"Checks if file with given name exists.\n",
        "\n",
        "    Returns file or None if it does not exist.\n",
        "    \"\"\"\n",
        "    files = client.files.list()\n",
        "    file = [ x for x in files if x.filename == name]\n",
        "    if file:\n",
        "        return file[0]\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "aPJtf1_GbB43"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Files\n",
        "\n",
        "Files can be added to assistants and messages. They are useful for retrieval and\n",
        "code interpreter tools."
      ],
      "metadata": {
        "id": "seqc5UCg7fNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = get_file(\"qualifikationsprofil.md\", client)\n",
        "if not file:\n",
        "    print(\"File does not exist yet, uploading it...\")\n",
        "    file = client.files.create(file=open(\"qualifikationsprofil.md\", \"rb\"), purpose=\"assistants\")\n",
        "    print(f\"New file uploaded ({file.id})\")\n",
        "else:\n",
        "    print(f\"File already exists ({file.id})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foGtGayXm3hK",
        "outputId": "54b4481f-c6be-422d-a07d-c6ebeccba829"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists (file-zjc8hngw5sMKoinHpZnYcBqa)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create/Update Assistant"
      ],
      "metadata": {
        "id": "m8r1Bn7x7pJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ASSISTANT_NAME = \"Bildungsberatungsassistent\"\n",
        "ASSISTANT_DESC = \"Assistent, der SchülerInnen bei der Schulauswahl hilft\"\n",
        "ASSISTANT_MODEL = \"gpt-4-1106-preview\"\n",
        "ASSISTANT_INSTRUCTIONS = \"\"\"\n",
        "Du bist ein Assistent, der SchülerInnen hilft, festzustellen, ob unsere Schule\n",
        "die richtige für sie ist. Dafür beantworte Fragen zum Qualifikationsprofil\n",
        "unserer AbsolventInnen auf Basis der Datei _qualifikationsprofil.md_. Beantworte\n",
        "NUR Fragen zum Qualifikationsprofil. Verwende NUR die Informationen aus der\n",
        "Datei.\n",
        "\"\"\"\n",
        "METADATA = {\"project\": \"OpenAI API Video Tutorial\"}\n",
        "\n",
        "assistant_data = {\n",
        "    \"model\": ASSISTANT_MODEL,\n",
        "    \"name\": ASSISTANT_NAME,\n",
        "    \"description\": ASSISTANT_DESC,\n",
        "    \"instructions\": ASSISTANT_INSTRUCTIONS,\n",
        "    \"metadata\": METADATA,\n",
        "    \"tools\": [{\"type\": \"retrieval\"}],\n",
        "    \"file_ids\": [file.id],\n",
        "}\n",
        "\n",
        "assistant = get_assistant(ASSISTANT_NAME, client)\n",
        "if not assistant:\n",
        "    print(\"Assistant does not exist yet, creating it...\")\n",
        "    assistant = client.beta.assistants.create(**assistant_data)\n",
        "    print(f\"New assistant created ({assistant.id})\")\n",
        "else:\n",
        "    print(f\"Assistant already exists ({assistant.id}), updating it...\")\n",
        "    assistant_data[\"assistant_id\"] = assistant.id\n",
        "    assistant = client.beta.assistants.update(**assistant_data)\n",
        "    print(f\"Assistant updated\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXKa8swkax9I",
        "outputId": "9c10b949-669b-4585-fc3d-219df71ae1e0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant does not exist yet, creating it...\n",
            "New assistant created (asst_11Wm8Ebxfn6hCvQztuvkg7df)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer Question With Retrieval Tool"
      ],
      "metadata": {
        "id": "yIg4dm6K7rfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pprint\n",
        "\n",
        "QUESTION = \"Haben AbsolventInnen der Schule eine Ausbildung bzgl. Projektmanagement?\"\n",
        "\n",
        "# Here we create the thread and the run separately. Note that there is an\n",
        "# API (https://platform.openai.com/docs/api-reference/runs/createThreadAndRun)\n",
        "# with which you could create a thread and start a run in one go.\n",
        "\n",
        "thread = client.beta.threads.create(\n",
        "    messages=[{\"role\": \"user\", \"content\": QUESTION}],\n",
        "    metadata=METADATA,\n",
        ")\n",
        "\n",
        "run = client.beta.threads.runs.create(\n",
        "    thread_id=thread.id,\n",
        "    assistant_id=assistant.id,\n",
        "    metadata=METADATA,\n",
        ")\n",
        "\n",
        "while True:\n",
        "    print(\"Sleeping for a moment to give OpenAI time to think...\")\n",
        "    time.sleep(3)\n",
        "\n",
        "    run = client.beta.threads.runs.retrieve(\n",
        "        run_id=run.id,\n",
        "        thread_id=thread.id,\n",
        "    )\n",
        "    print(f\"Run status: {run.status}\")\n",
        "\n",
        "    # Note that the thread API returns a paged result. To keep things simple,\n",
        "    # we assume that no paging is necessary (i.e. we have less than 100\n",
        "    # steps).\n",
        "    steps = client.beta.threads.runs.steps.list(\n",
        "        run_id=run.id,\n",
        "        thread_id=thread.id,\n",
        "        limit=100\n",
        "    )\n",
        "    for step in steps:\n",
        "        print(f\"\\t{step.type}: {step.status}\")\n",
        "\n",
        "    if run.status == \"completed\":\n",
        "        break;\n",
        "\n",
        "# Get the last message and print it on the screen\n",
        "messages = client.beta.threads.messages.list(\n",
        "    thread_id=thread.id,\n",
        "    limit=100)\n",
        "pprint.pprint(messages.data[0].content[0].text.value)\n",
        "\n",
        "# Note that you can get annotations, too. In the case of the retrieval tool,\n",
        "# annotations contain sources from uploaded files.\n",
        "messages.data[0].content[0].text.annotations[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPvu5_tqxB9p",
        "outputId": "0aa77fad-f520-4cd3-ce4c-9180e52d6851"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sleeping for a moment to give OpenAI time to think...\n",
            "Run status: in_progress\n",
            "\ttool_calls: in_progress\n",
            "Sleeping for a moment to give OpenAI time to think...\n",
            "Run status: in_progress\n",
            "\ttool_calls: in_progress\n",
            "Sleeping for a moment to give OpenAI time to think...\n",
            "Run status: in_progress\n",
            "\tmessage_creation: in_progress\n",
            "\ttool_calls: completed\n",
            "Sleeping for a moment to give OpenAI time to think...\n",
            "Run status: in_progress\n",
            "\tmessage_creation: in_progress\n",
            "\ttool_calls: completed\n",
            "Sleeping for a moment to give OpenAI time to think...\n",
            "Run status: completed\n",
            "\tmessage_creation: completed\n",
            "\ttool_calls: completed\n",
            "('Ja, AbsolventInnen unserer Schule erhalten eine Ausbildung im Bereich '\n",
            " 'Projektmanagement. Das Wissen und die Erfahrungen im Projektmanagement sind '\n",
            " 'Teil der unternehmerischen Kompetenzen, die in den Pflichtgegenständen '\n",
            " '„Informationstechnische Projekte“ sowie „Wirtschaft und Recht“ vermittelt '\n",
            " 'werden【7†Quelle】.')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextAnnotationFileCitation(end_index=307, file_citation=TextAnnotationFileCitationFileCitation(file_id='file-zjc8hngw5sMKoinHpZnYcBqa', quote='die betriebswirtschaftliche und rechtliche Kenntnisse, Wissen und Erfahrungen im Projektmanagement sowie Managementkenntnisse einschließen und in den Pflichtgegenständen „Informationstechnische Projekte“ sowie „Wirtschaft und Recht“ vermittelt werden'), start_index=297, text='【7†Quelle】', type='file_citation')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}